{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios ensembling\n",
    "En este ejercicio vas a realizar prediciones sobre un dataset de ciudadanos indios diabéticos. Se trata de un problema de clasificación en el que intentaremos predecir 1 (diabético) 0 (no diabético). Todas las variables son numércias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga las librerias que consideres comunes al notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lee los datos de [esta direccion](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
    "Los nombres de columnas son:\n",
    "```Python\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0       6   148    72    35     0  33.6  0.627   50      1\n",
       "1       1    85    66    29     0  26.6  0.351   31      0\n",
       "2       8   183    64     0     0  23.3  0.672   32      1\n",
       "3       1    89    66    23    94  28.1  0.167   21      0\n",
       "4       0   137    40    35   168  43.1  2.288   33      1\n",
       "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
       "763    10   101    76    48   180  32.9  0.171   63      0\n",
       "764     2   122    70    27     0  36.8  0.340   27      0\n",
       "765     5   121    72    23   112  26.2  0.245   30      0\n",
       "766     1   126    60     0     0  30.1  0.349   47      1\n",
       "767     1    93    70    31     0  30.4  0.315   23      0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",names=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de agregar los nombres de las columnas\n",
    "# df.columns = list(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0       6   148    72    35     0  33.6  0.627   50      1\n",
       "1       1    85    66    29     0  26.6  0.351   31      0\n",
       "2       8   183    64     0     0  23.3  0.672   32      1\n",
       "3       1    89    66    23    94  28.1  0.167   21      0\n",
       "4       0   137    40    35   168  43.1  2.288   33      1\n",
       "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
       "763    10   101    76    48   180  32.9  0.171   63      0\n",
       "764     2   122    70    27     0  36.8  0.340   27      0\n",
       "765     5   121    72    23   112  26.2  0.245   30      0\n",
       "766     1   126    60     0     0  30.1  0.349   47      1\n",
       "767     1    93    70    31     0  30.4  0.315   23      0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   preg    768 non-null    int64  \n",
      " 1   plas    768 non-null    int64  \n",
      " 2   pres    768 non-null    int64  \n",
      " 3   skin    768 non-null    int64  \n",
      " 4   test    768 non-null    int64  \n",
      " 5   mass    768 non-null    float64\n",
      " 6   pedi    768 non-null    float64\n",
      " 7   age     768 non-null    int64  \n",
      " 8   class   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        test        mass  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "             pedi         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bagging\n",
    "Para este apartado tendrás que crear un ensemble utilizando la técnica de bagging ([BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)), mediante la cual combinarás 100 [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Recuerda utilizar también [cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) con 10 kfolds.\n",
    "\n",
    "**Para este apartado y siguientes, no hace falta que dividas en train/test**, por hacerlo más sencillo. Simplemente divide tus datos en features y target.\n",
    "\n",
    "Establece una semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa los datos en features (X) y target (y)\n",
    "# Nuestro target es df[\"class\"]\n",
    "\n",
    "features = df.drop(columns=[\"class\"])\n",
    "target = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# Muestra el shape de ambos conjuntos\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a grabar la semilla 7 para todos los modelos en la variable seed\n",
    "\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia un Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmonotonic_cst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseDecisionTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A decision tree classifier.\n",
      "\n",
      "    Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      "        Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      "\n",
      "    splitter : {\"best\", \"random\"}, default=\"best\"\n",
      "        The strategy used to choose the split at each node. Supported\n",
      "        strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "        the best random split.\n",
      "\n",
      "    max_depth : int, default=None\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float or {\"sqrt\", \"log2\"}, default=None\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "            - If int, then consider `max_features` features at each split.\n",
      "            - If float, then `max_features` is a fraction and\n",
      "              `max(1, int(max_features * n_features_in_))` features are considered at\n",
      "              each split.\n",
      "            - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"log2\", then `max_features=log2(n_features)`.\n",
      "            - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the randomness of the estimator. The features are always\n",
      "        randomly permuted at each split, even if ``splitter`` is set to\n",
      "        ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
      "        select ``max_features`` at random at each split before finding the best\n",
      "        split among them. But the best found split may vary across different\n",
      "        runs, even if ``max_features=n_features``. That is the case, if the\n",
      "        improvement of the criterion is identical for several splits and one\n",
      "        split has to be selected at random. To obtain a deterministic behaviour\n",
      "        during fitting, ``random_state`` has to be fixed to an integer.\n",
      "        See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    class_weight : dict, list of dict or \"balanced\", default=None\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If None, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    monotonic_cst : array-like of int of shape (n_features), default=None\n",
      "        Indicates the monotonicity constraint to enforce on each feature.\n",
      "          - 1: monotonic increase\n",
      "          - 0: no constraint\n",
      "          - -1: monotonic decrease\n",
      "\n",
      "        If monotonic_cst is None, no constraints are applied.\n",
      "\n",
      "        Monotonicity constraints are not supported for:\n",
      "          - multiclass classifications (i.e. when `n_classes > 2`),\n",
      "          - multioutput classifications (i.e. when `n_outputs_ > 1`),\n",
      "          - classifications trained on data with missing values.\n",
      "\n",
      "        The constraints hold over the probability of the positive class.\n",
      "\n",
      "        Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.\n",
      "\n",
      "        .. versionadded:: 1.4\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
      "        The classes labels (single output problem),\n",
      "        or a list of arrays of class labels (multi-output problem).\n",
      "\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The impurity-based feature importances.\n",
      "        The higher, the more important the feature.\n",
      "        The importance of a feature is computed as the (normalized)\n",
      "        total reduction of the criterion brought by that feature.  It is also\n",
      "        known as the Gini importance [4]_.\n",
      "\n",
      "        Warning: impurity-based feature importances can be misleading for\n",
      "        high cardinality features (many unique values). See\n",
      "        :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    n_classes_ : int or list of int\n",
      "        The number of classes (for single output problems),\n",
      "        or a list containing the number of classes for each\n",
      "        output (for multi-output problems).\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    tree_ : Tree instance\n",
      "        The underlying Tree object. Please refer to\n",
      "        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "        for basic usage of these attributes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DecisionTreeRegressor : A decision tree regressor.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The :meth:`predict` method operates using the :func:`numpy.argmax`\n",
      "    function on the outputs of :meth:`predict_proba`. This means that in\n",
      "    case the highest predicted probabilities are tied, the classifier will\n",
      "    predict the tied class with the lowest index in :term:`classes_`.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      "\n",
      "    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      "           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      "\n",
      "    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      "           Learning\", Springer, 2009.\n",
      "\n",
      "    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      "           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> from sklearn.tree import DecisionTreeClassifier\n",
      "    >>> clf = DecisionTreeClassifier(random_state=0)\n",
      "    >>> iris = load_iris()\n",
      "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      "    ...                             # doctest: +SKIP\n",
      "    ...\n",
      "    array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      "            0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mBaseDecisionTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"criterion\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mStrOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"log_loss\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"class_weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStrOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"best\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmonotonic_cst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmonotonic_cst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonotonic_cst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mccp_alpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Build a decision tree classifier from the training set (X, y).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csc_matrix``.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The target values (class labels) as integers or strings.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If None, then samples are equally weighted. Splits\n",
      "            that would create child nodes with net zero or negative weight are\n",
      "            ignored while searching for a split in each node. Splits are also\n",
      "            ignored if they would result in any single class carrying a\n",
      "            negative weight in either child node.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you're doing.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : DecisionTreeClassifier\n",
      "            Fitted estimator.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "        The predicted class probability is the fraction of samples of the same\n",
      "        class in a leaf.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you're doing.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n",
      "            such arrays if n_outputs > 1\n",
      "            The class probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mall_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mall_proba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class log-probabilities of the input samples X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n",
      "            such arrays if n_outputs > 1\n",
      "            The class log-probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# XXX: nan is only support for dense arrays, but we set this for common test to\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# pass, specifically: check_estimators_nan_inf\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mallow_nan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"best\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"log_loss\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"allow_nan\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\vipre\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     ExtraTreeClassifier"
     ]
    }
   ],
   "source": [
    "DecisionTreeClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia un Bagging Classifier cuyo base estimator sea el DecisionTreeClassifier() , el número de estimadores sea 100 y el random state sea la semilla seed que hemos creado\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth=3,random_state=seed)\n",
    "\n",
    "bag_clf = BaggingClassifier (n_estimators = 100,\n",
    "                             estimator=estimator) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia 10 KFolds en la variable kfold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state= seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80519481, 0.75324675, 0.7012987 , 0.79220779, 0.81818182,\n",
       "       0.79220779, 0.71428571, 0.71428571, 0.76315789, 0.72368421])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálcula el cross validation score del Bagging Classifier con X e y, el cv sea igual a kfold y el scoring sea 'accuracy'\n",
    "# Recuerda que el cross validation score se graba en una nueva variable, dale un nombre adecuado y no la borres, la necesitarás al final del ejercicio\n",
    "\n",
    "\n",
    "cv = cross_val_score( estimator=bag_clf,\n",
    "                X = features,\n",
    "                y = target,\n",
    "                cv=kfold,\n",
    "                scoring=\"accuracy\"\n",
    "                )\n",
    "\n",
    "cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757775119617225"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtén la media del cross validation score para el Bagging Classifier\n",
    "# Simplemente en la variable en la que guardaste el CV usa el método < .mean() >\n",
    "\n",
    "\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7720437457279563"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest\n",
    "En este caso entrena un [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) con 100 árboles y un `max_features` de 3. También con validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia un Random Forest Classifier con 100 árboles, max features de 3 y que el random state sea la seed que hemos creado\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100,\n",
    "                       max_features= 3,\n",
    "                       random_state=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77922078, 0.75324675, 0.7012987 , 0.75324675, 0.80519481,\n",
       "       0.80519481, 0.67532468, 0.80519481, 0.80263158, 0.71052632])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cálcula el cross validation score del Random Forest Classifier con X e y, y que el cv sea igual a kfold\n",
    "# Recuerda que el cross validation score se graba en una nueva variable, dale un nombre adecuado y no la borres, la necesitarás al final del ejercicio\n",
    "\n",
    "cv_2_rnd = cross_val_score( estimator=rnd_clf,\n",
    "                X = features,\n",
    "                y = target,\n",
    "                cv=kfold,\n",
    "                scoring=\"accuracy\"\n",
    "                )\n",
    "\n",
    "cv_2_rnd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759107997265892"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtén la media del cross validation score para el Random Forest Classifier\n",
    "\n",
    "cv_2_rnd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733766233766234"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. AdaBoost\n",
    "Implementa un [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) con 30 árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_RoutingNotSupportedMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseWeightBoosting\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"An AdaBoost classifier.\n",
      "\n",
      "    An AdaBoost [1]_ classifier is a meta-estimator that begins by fitting a\n",
      "    classifier on the original dataset and then fits additional copies of the\n",
      "    classifier on the same dataset but where the weights of incorrectly\n",
      "    classified instances are adjusted such that subsequent classifiers focus\n",
      "    more on difficult cases.\n",
      "\n",
      "    This class implements the algorithm based on [2]_.\n",
      "\n",
      "    Read more in the :ref:`User Guide <adaboost>`.\n",
      "\n",
      "    .. versionadded:: 0.14\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : object, default=None\n",
      "        The base estimator from which the boosted ensemble is built.\n",
      "        Support for sample weighting is required, as well as proper\n",
      "        ``classes_`` and ``n_classes_`` attributes. If ``None``, then\n",
      "        the base estimator is :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      "        initialized with `max_depth=1`.\n",
      "\n",
      "        .. versionadded:: 1.2\n",
      "           `base_estimator` was renamed to `estimator`.\n",
      "\n",
      "    n_estimators : int, default=50\n",
      "        The maximum number of estimators at which boosting is terminated.\n",
      "        In case of perfect fit, the learning procedure is stopped early.\n",
      "        Values must be in the range `[1, inf)`.\n",
      "\n",
      "    learning_rate : float, default=1.0\n",
      "        Weight applied to each classifier at each boosting iteration. A higher\n",
      "        learning rate increases the contribution of each classifier. There is\n",
      "        a trade-off between the `learning_rate` and `n_estimators` parameters.\n",
      "        Values must be in the range `(0.0, inf)`.\n",
      "\n",
      "    algorithm : {'SAMME', 'SAMME.R'}, default='SAMME.R'\n",
      "        If 'SAMME.R' then use the SAMME.R real boosting algorithm.\n",
      "        ``estimator`` must support calculation of class probabilities.\n",
      "        If 'SAMME' then use the SAMME discrete boosting algorithm.\n",
      "        The SAMME.R algorithm typically converges faster than SAMME,\n",
      "        achieving a lower test error with fewer boosting iterations.\n",
      "\n",
      "        .. deprecated:: 1.4\n",
      "            `\"SAMME.R\"` is deprecated and will be removed in version 1.6.\n",
      "            '\"SAMME\"' will become the default.\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the random seed given at each `estimator` at each\n",
      "        boosting iteration.\n",
      "        Thus, it is only used when `estimator` exposes a `random_state`.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    estimator_ : estimator\n",
      "        The base estimator from which the ensemble is grown.\n",
      "\n",
      "        .. versionadded:: 1.2\n",
      "           `base_estimator_` was renamed to `estimator_`.\n",
      "\n",
      "    estimators_ : list of classifiers\n",
      "        The collection of fitted sub-estimators.\n",
      "\n",
      "    classes_ : ndarray of shape (n_classes,)\n",
      "        The classes labels.\n",
      "\n",
      "    n_classes_ : int\n",
      "        The number of classes.\n",
      "\n",
      "    estimator_weights_ : ndarray of floats\n",
      "        Weights for each estimator in the boosted ensemble.\n",
      "\n",
      "    estimator_errors_ : ndarray of floats\n",
      "        Classification error for each estimator in the boosted\n",
      "        ensemble.\n",
      "\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The impurity-based feature importances if supported by the\n",
      "        ``estimator`` (when based on decision trees).\n",
      "\n",
      "        Warning: impurity-based feature importances can be misleading for\n",
      "        high cardinality features (many unique values). See\n",
      "        :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    AdaBoostRegressor : An AdaBoost regressor that begins by fitting a\n",
      "        regressor on the original dataset and then fits additional copies of\n",
      "        the regressor on the same dataset but where the weights of instances\n",
      "        are adjusted according to the error of the current prediction.\n",
      "\n",
      "    GradientBoostingClassifier : GB builds an additive model in a forward\n",
      "        stage-wise fashion. Regression trees are fit on the negative gradient\n",
      "        of the binomial or multinomial deviance loss function. Binary\n",
      "        classification is a special case where only a single regression tree is\n",
      "        induced.\n",
      "\n",
      "    sklearn.tree.DecisionTreeClassifier : A non-parametric supervised learning\n",
      "        method used for classification.\n",
      "        Creates a model that predicts the value of a target variable by\n",
      "        learning simple decision rules inferred from the data features.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Y. Freund, R. Schapire, \"A Decision-Theoretic Generalization of\n",
      "           on-Line Learning and an Application to Boosting\", 1995.\n",
      "\n",
      "    .. [2] :doi:`J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class adaboost.\"\n",
      "           Statistics and its Interface 2.3 (2009): 349-360.\n",
      "           <10.4310/SII.2009.v2.n3.a8>`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.ensemble import AdaBoostClassifier\n",
      "    >>> from sklearn.datasets import make_classification\n",
      "    >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      "    ...                            n_informative=2, n_redundant=0,\n",
      "    ...                            random_state=0, shuffle=False)\n",
      "    >>> clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0)\n",
      "    >>> clf.fit(X, y)\n",
      "    AdaBoostClassifier(algorithm='SAMME', n_estimators=100, random_state=0)\n",
      "    >>> clf.predict([[0, 0, 0, 0]])\n",
      "    array([1])\n",
      "    >>> clf.score(X, y)\n",
      "    0.96...\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# TODO(1.6): Modify _parameter_constraints for \"algorithm\" to only check\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# for \"SAMME\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mBaseWeightBoosting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"algorithm\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mStrOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"SAMME\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SAMME.R\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# TODO(1.6): Change default \"algorithm\" value to \"SAMME\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"SAMME.R\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Check the estimator and set the estimator_ attribute.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# TODO(1.6): Remove, as \"SAMME.R\" value for \"algorithm\" param will be\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# removed in 1.6\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# SAMME-R requires predict_proba-enabled base estimators\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"SAMME\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"The SAMME.R algorithm (the default) is deprecated and will be\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\" removed in 1.6. Use the SAMME algorithm to circumvent this\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\" warning.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"predict_proba\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"AdaBoostClassifier with algorithm='SAMME.R' requires \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"that the weak learner supports the calculation of class \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"probabilities with a predict_proba method.\\n\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"Please change the base estimator or set \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"algorithm='SAMME' instead.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_fit_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sample_weight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m doesn't support sample_weight.\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# TODO(1.6): Redefine the scope of the `_boost` and `_boost_discrete`\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# functions to be the same since SAMME will be the default value for the\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# \"algorithm\" parameter in version 1.6. Thus, a distinguishing function is\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# no longer needed. (Or adjust code here, if another algorithm, shall be\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# used instead of SAMME.R.)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Implement a single boost.\n",
      "\n",
      "        Perform a single boost according to the real multi-class SAMME.R\n",
      "        algorithm or to the discrete SAMME algorithm and return the updated\n",
      "        sample weights.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        iboost : int\n",
      "            The index of the current boost iteration.\n",
      "\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples.\n",
      "\n",
      "        y : array-like of shape (n_samples,)\n",
      "            The target values (class labels).\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,)\n",
      "            The current sample weights.\n",
      "\n",
      "        random_state : RandomState instance\n",
      "            The RandomState instance used if the base estimator accepts a\n",
      "            `random_state` attribute.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sample_weight : array-like of shape (n_samples,) or None\n",
      "            The reweighted sample weights.\n",
      "            If None then boosting has terminated early.\n",
      "\n",
      "        estimator_weight : float\n",
      "            The weight for the current boost.\n",
      "            If None then boosting has terminated early.\n",
      "\n",
      "        estimator_error : float\n",
      "            The classification error for the current boost.\n",
      "            If None then boosting has terminated early.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"SAMME.R\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_discrete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# TODO(1.6): Remove function. The `_boost_real` function won't be used any\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# longer, because the SAMME.R algorithm will be deprecated in 1.6.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classes_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Instances incorrectly classified\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mincorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_predict\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Error fraction\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Stop if classification is perfect\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mestimator_error\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Construct y coding as described in Zhu et al [2]:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#    y_k = 1 if c == k else -1 / (K - 1)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# where K == n_classes_ and c, k in [0, K) are indices along the second\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# axis of the y coding with c being the index corresponding to the true\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# class label.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my_coding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_codes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Displace zero probabilities so the log is defined.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Also fix negative elements which may occur with\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# negative sample weights.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_predict_proba\u001b[0m  \u001b[1;31m# alias for readability\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Boost weight using multi-class AdaBoost SAMME.R alg\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m*\u001b[0m \u001b[0mxlogy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_coding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Only boost the weights if it will fit again\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# Only boost positive weights\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mestimator_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mestimator_weight\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_error\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_boost_discrete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Implement a single boost using the SAMME discrete algorithm.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classes_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Instances incorrectly classified\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mincorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_predict\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Error fraction\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Stop if classification is perfect\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mestimator_error\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Stop if the error is at least as bad as random guessing\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mestimator_error\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"BaseClassifier in AdaBoostClassifier \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"ensemble is worse than random, ensemble \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"can not be fit.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Boost weight using multi-class AdaBoost SAMME alg\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mestimator_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mestimator_error\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mestimator_error\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Only boost the weights if it will fit again\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# Only boost positive weights\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m+\u001b[0m \u001b[0mestimator_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_error\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict classes for X.\n",
      "\n",
      "        The predicted class of an input sample is computed as the weighted mean\n",
      "        prediction of the classifiers in the ensemble.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The predicted classes.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Return staged predictions for X.\n",
      "\n",
      "        The predicted class of an input sample is computed as the weighted mean\n",
      "        prediction of the classifiers in the ensemble.\n",
      "\n",
      "        This generator method yields the ensemble prediction after each\n",
      "        iteration of boosting and therefore allows monitoring, such as to\n",
      "        determine the prediction on a test set after each boost.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Yields\n",
      "        ------\n",
      "        y : generator of ndarray of shape (n_samples,)\n",
      "            The predicted classes.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstaged_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstaged_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Compute the decision function of ``X``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        score : ndarray of shape of (n_samples, k)\n",
      "            The decision function of the input samples. The order of\n",
      "            outputs is the same as that of the :term:`classes_` attribute.\n",
      "            Binary classification is a special cases with ``k == 1``,\n",
      "            otherwise ``k==n_classes``. For binary classification,\n",
      "            values closer to -1 or 1 mean more like the first or second\n",
      "            class in ``classes_``, respectively.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# TODO(1.6): Remove, because \"algorithm\" param will be deprecated in 1.6\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"SAMME.R\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0m_samme_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_weights_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpred\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_weights_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstaged_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Compute decision function of ``X`` for each boosting iteration.\n",
      "\n",
      "        This method allows monitoring (i.e. determine error on testing set)\n",
      "        after each boosting iteration.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Yields\n",
      "        ------\n",
      "        score : generator of ndarray of shape (n_samples, k)\n",
      "            The decision function of the input samples. The order of\n",
      "            outputs is the same of that of the :term:`classes_` attribute.\n",
      "            Binary classification is a special cases with ``k == 1``,\n",
      "            otherwise ``k==n_classes``. For binary classification,\n",
      "            values closer to -1 or 1 mean more like the first or second\n",
      "            class in ``classes_``, respectively.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_weights_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnorm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# TODO(1.6): Remove, because \"algorithm\" param will be deprecated in\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# 1.6\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"SAMME.R\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcurrent_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_samme_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcurrent_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_pred\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mpred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurrent_pred\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtmp_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtmp_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtmp_pred\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_compute_proba_from_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Compute probabilities from the decision function.\n",
      "\n",
      "        This is based eq. (15) of [1] where:\n",
      "            p(y=c|X) = exp((1 / K-1) f_c(X)) / sum_k(exp((1 / K-1) f_k(X)))\n",
      "                     = softmax((1 / K-1) * f(X))\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class AdaBoost\",\n",
      "               2009.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdecision\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class probabilities for X.\n",
      "\n",
      "        The predicted class probabilities of an input sample is computed as\n",
      "        the weighted mean predicted class probabilities of the classifiers\n",
      "        in the ensemble.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        p : ndarray of shape (n_samples, n_classes)\n",
      "            The class probabilities of the input samples. The order of\n",
      "            outputs is the same of that of the :term:`classes_` attribute.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_proba_from_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstaged_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class probabilities for X.\n",
      "\n",
      "        The predicted class probabilities of an input sample is computed as\n",
      "        the weighted mean predicted class probabilities of the classifiers\n",
      "        in the ensemble.\n",
      "\n",
      "        This generator method yields the ensemble predicted class probabilities\n",
      "        after each iteration of boosting and therefore allows monitoring, such\n",
      "        as to determine the predicted class probabilities on a test set after\n",
      "        each boost.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Yields\n",
      "        ------\n",
      "        p : generator of ndarray of shape (n_samples,)\n",
      "            The class probabilities of the input samples. The order of\n",
      "            outputs is the same of that of the :term:`classes_` attribute.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mdecision\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstaged_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_proba_from_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class log-probabilities for X.\n",
      "\n",
      "        The predicted class log-probabilities of an input sample is computed as\n",
      "        the weighted mean predicted class log-probabilities of the classifiers\n",
      "        in the ensemble.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      "            DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        p : ndarray of shape (n_samples, n_classes)\n",
      "            The class probabilities of the input samples. The order of\n",
      "            outputs is the same of that of the :term:`classes_` attribute.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\vipre\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "AdaBoostClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vipre\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.76623377, 0.71428571, 0.71428571, 0.79220779, 0.79220779,\n",
       "       0.74025974, 0.68831169, 0.77922078, 0.80263158, 0.76315789])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia un AdaBoost Classifier con 30 árboles y que el random state sea la seed que hemos creado\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=30, random_state=seed)\n",
    "\n",
    "# Cálcula el cross validation score del AdaBoost Classifier con X e y, y que el cv sea igual a kfold\n",
    "# Recuerda que el cross validation score se graba en una nueva variable, dale un nombre adecuado y no la borres, la necesitarás al final del ejercicio\n",
    "cv_3_ada = cross_val_score(estimator=ada_clf,\n",
    "                      X= features,\n",
    "                      y = target,\n",
    "                      scoring=\"accuracy\",\n",
    "                      cv= kfold                      \n",
    "                      )\n",
    "cv_3_ada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7552802460697198"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtén la media del cross validation score para el AdaBoost Classifier\n",
    "\n",
    "\n",
    "cv_3_ada.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760457963089542"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GradientBoosting\n",
    "Implementa un [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) con 100 estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77922078, 0.76623377, 0.67532468, 0.77922078, 0.79220779,\n",
       "       0.76623377, 0.63636364, 0.80519481, 0.82894737, 0.75      ])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia un GradientBoosting Classifier con 100 estimadores y que el random state sea la seed que hemos creado\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators= 100,\n",
    "                                    random_state= seed)\n",
    "\n",
    "# Cálcula el cross validation score del GradientBoosting Classifier con X e y, y que el cv sea igual a kfold\n",
    "# Recuerda que el cross validation score se graba en una nueva variable, dale un nombre adecuado y no la borres, la necesitarás al final del ejercicio\n",
    "\n",
    "cv_4_gb = cross_val_score(estimator= gb_clf,\n",
    "                         X = features,\n",
    "                         y = target,\n",
    "                         cv= kfold,\n",
    "                         scoring=\"accuracy\",\n",
    "                         )\n",
    "\n",
    "cv_4_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578947368421053"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La misma vaina que estamos haciendo, saca el mean() de la variable del cross_validation  :)\n",
    "# Jajjajaja\n",
    "\n",
    "cv_4_gb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681989063568012"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. XGBoost\n",
    "Para este apartado utiliza un [XGBoostClassifier](https://docs.getml.com/latest/api/getml.predictors.XGBoostClassifier.html) con 100 estimadores. XGBoost no forma parte de la suite de modelos de sklearn, por lo que tendrás que instalarlo con pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7012987 , 0.71428571, 0.68831169, 0.76623377, 0.74025974,\n",
       "       0.72727273, 0.63636364, 0.79220779, 0.78947368, 0.71052632])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia un XGBoost Classifier con 100 estimadores y que el random state sea la seed que hemos creado\n",
    "\n",
    "xgb_clf = XGBClassifier( n_estimators= 100,\n",
    "                        random_state = seed\n",
    ")\n",
    "\n",
    "# Cálcula el cross validation score del XGBoost Classifier con X e y, y que el cv sea igual a kfold\n",
    "\n",
    "cv_5_xgb = cross_val_score( estimator=xgb_clf,\n",
    "                          X = features,\n",
    "                         y = target,\n",
    "                         cv= kfold,\n",
    "                         scoring=\"accuracy\",\n",
    "                         )\n",
    "\n",
    "cv_5_xgb\n",
    "# Recuerda que el cross validation score se graba en una nueva variable, dale un nombre adecuado y no la borres, la necesitarás al final del ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266233766233766"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la mean de la wea que acabamos de hacer\n",
    "\n",
    "cv_5_xgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395591250854407"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Resultados\n",
    "Crea un series con los resultados y sus algoritmos, ordenándolos de mayor a menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest       0.759108\n",
       "GradientBoosting    0.757895\n",
       "Bagging DT          0.757775\n",
       "Ada Boost           0.755280\n",
       "XGBoost             0.726623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [cv.mean(), cv_2_rnd.mean(), cv_3_ada.mean(), cv_4_gb.mean(), cv_5_xgb.mean()]\n",
    "models = ['Bagging DT', \"Random Forest\", \"Ada Boost\", \"GradientBoosting\", \"XGBoost\"]\n",
    "\n",
    "resultados = pd.Series(result, models).sort_values(ascending=False)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest       0.773377\n",
       "Bagging DT          0.772044\n",
       "GradientBoosting    0.768199\n",
       "Ada Boost           0.760458\n",
       "XGBoost             0.739559\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [results_cv.mean(), results_cv_rfc.mean(), results_cv_ada.mean(), results_cv_gb.mean(), results_cv_xgb.mean()]\n",
    "models = ['Bagging DT', \"Random Forest\", \"Ada Boost\", \"GradientBoosting\", \"XGBoost\"]\n",
    "\n",
    "resultados = pd.Series(result, models).sort_values(ascending=False)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quieres seguir diviertiendote puedes hacer lo siguiente:\n",
    "\n",
    "# Continue with:\n",
    "# split train test\n",
    "# .fit\n",
    "# evaluation with test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7f22e608a9410c9a00adbb49e3cb6a72010c497ae6b30c9496ff58de178a89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
